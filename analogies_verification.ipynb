{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verifying \"Analogies Explained\" via Synthetic Data\n",
    "\n",
    "This notebook verifies the paper by constructing synthetic co-occurrence data where paraphrases hold by design.\n",
    "\n",
    "**Core equation:** For $w^* = W$ (e.g., king = {man, royalty}):\n",
    "\n",
    "$$\\text{PMI}(c, w^*) = \\sum_{w \\in W} \\text{PMI}(c, w) + \\rho(c) + \\sigma(c) - \\tau$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Generation.** We sample windows so that `king` and `{man, royalty}` share identical context distributions, enforcing paraphrase error $\\rho \\approx 0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(n_windows=100_000, x=1/6, seed=42, scale=10):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    \n",
    "    NEUTRAL = [f\"neutral_{i}\" for i in range(10 * scale)]\n",
    "    MAN = [f\"man_{i}\" for i in range(4 * scale)]\n",
    "    WOMAN = [f\"woman_{i}\" for i in range(4 * scale)]\n",
    "    ROYALTY = [f\"royalty_{i}\" for i in range(2 * scale)]\n",
    "    \n",
    "    CONTEXTS = {\n",
    "        'man': MAN + NEUTRAL,\n",
    "        'woman': WOMAN + NEUTRAL,\n",
    "        'king': MAN + ROYALTY,\n",
    "        'queen': WOMAN + ROYALTY,\n",
    "        '<royalty>': ROYALTY,\n",
    "        ('<royalty>', 'man'): MAN + ROYALTY,\n",
    "        ('<royalty>', 'woman'): WOMAN + ROYALTY,\n",
    "    }\n",
    "    TARGETS = ['man', 'woman', 'king', 'queen', '<royalty>']\n",
    "    \n",
    "    counts = defaultdict(int)\n",
    "    paired_counts = defaultdict(int)\n",
    "    target_conditioned_counts = defaultdict(lambda: defaultdict(int))\n",
    "    \n",
    "    for _ in range(n_windows):        \n",
    "        if random.random() < 5 * x:\n",
    "            targets = [random.choice(TARGETS)]\n",
    "            ctx_key = targets[0]\n",
    "        else:\n",
    "            targets = random.choice([['man', '<royalty>'], ['woman', '<royalty>']])\n",
    "            ctx_key = tuple(sorted(targets))\n",
    "            paired_counts[ctx_key] += 1\n",
    "        \n",
    "        context = list(set(random.sample(CONTEXTS[ctx_key], k=4)))\n",
    "        \n",
    "        for w0 in targets:\n",
    "            counts[w0] += 1\n",
    "            for w1 in context:\n",
    "                paired_counts[tuple(sorted((w0, w1)))] += 1\n",
    "        \n",
    "        for i, w1 in enumerate(context):\n",
    "            counts[w1] += 1\n",
    "            target_conditioned_counts[ctx_key][w1] += 1\n",
    "            for j in range(i+1, len(context)):\n",
    "                w2 = context[j]\n",
    "                paired_counts[tuple(sorted((w1, w2)))] += 1\n",
    "                \n",
    "    return counts, paired_counts, target_conditioned_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PMI and Embeddings**\n",
    "\n",
    "\n",
    "Laplace smoothing ($\\alpha$) prevents log(0) but introduces bias. Different probability estimates use different normalizations:\n",
    "\n",
    "For $p(c|w)$ from co-occurrence matrix:\n",
    "$$p(c|w) = \\frac{\\alpha}{N + \\alpha n}$$\n",
    "\n",
    "For $p(c|W)$ from triple counts (pair has ~3 context slots):\n",
    "$$p(c|W) = \\frac{0.5\\alpha}{(p/2) \\cdot N + 0.5\\alpha n}$$\n",
    "\n",
    "Using inconsistent smoothing inflates the residual because many tokens accumulate small biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_all(counts, paired_counts, target_conditioned_counts, total, alpha=1, rank=50):\n",
    "    vocab = sorted(counts.keys())\n",
    "    word2idx = {w: i for i, w in enumerate(vocab)}\n",
    "    n = len(vocab)\n",
    "    \n",
    "    p_w = np.array([(counts[w] + alpha) / (total + alpha * n) for w in vocab])\n",
    "    \n",
    "    p_cw = np.zeros((n, n))\n",
    "    for (w1, w2), cnt in paired_counts.items():\n",
    "        i, j = word2idx[w1], word2idx[w2]\n",
    "        p_cw[i, j] = cnt\n",
    "        p_cw[j, i] = cnt\n",
    "    p_cw = (p_cw + alpha) / (total + alpha * n)\n",
    "    \n",
    "    PMI = np.log(p_cw / (p_w[:, None] * p_w[None, :]))\n",
    "    \n",
    "    PAIRS = [('<royalty>', 'man'), ('<royalty>', 'woman')]\n",
    "    p_W = {pair: paired_counts[pair] / total for pair in PAIRS}\n",
    "    \n",
    "    p_c_given_W = {}\n",
    "    for pair in PAIRS:\n",
    "        tc = target_conditioned_counts[pair]\n",
    "        sz = paired_counts[pair]\n",
    "        p_c_given_W[pair] = {c: (tc.get(c, 0) + 0.5 * alpha) / (sz + alpha * n / 12) for c in vocab}\n",
    "    \n",
    "    U, S, Vt = np.linalg.svd(PMI, full_matrices=False)\n",
    "    sqrt_S = np.sqrt(np.abs(S[:rank])) * np.sign(S[:rank])\n",
    "    W = (U[:, :rank] * sqrt_S).T\n",
    "    C = (Vt[:rank, :].T * sqrt_S).T\n",
    "    C_dag = np.linalg.pinv(C.T)\n",
    "    \n",
    "    return PMI, p_cw, p_w, p_c_given_W, p_W, W, C_dag, word2idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Verification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify(PMI, p_cw, p_w, p_c_given_W, p_W, W, C_dag, word2idx):\n",
    "    n = len(word2idx)\n",
    "    idx = word2idx\n",
    "    vocab = {i: w for w, i in idx.items()}\n",
    "    log = lambda x: np.log(np.maximum(x, 1e-15))\n",
    "    \n",
    "    p_given_c = {w: p_cw[:, i] / p_w[i] for w, i in idx.items()}\n",
    "    \n",
    "    PAIRS = [('<royalty>', 'man'), ('<royalty>', 'woman')]\n",
    "    p_cW = {pair: np.array([p_c_given_W[pair][vocab[i]] for i in range(n)]) for pair in PAIRS}\n",
    "    p_Wc = {pair: p_cW[pair] * p_W[pair] / p_w for pair in PAIRS}\n",
    "    \n",
    "    CASES = [('king', 'man', '<royalty>', ('<royalty>', 'man')),\n",
    "             ('queen', 'woman', '<royalty>', ('<royalty>', 'woman'))]\n",
    "    \n",
    "    for space_name, vecs, project, s in [(\"PMI space\", PMI, lambda x: x, \"I\"),\n",
    "                                         (\"Embedding space\", W, lambda x: C_dag @ x, \"C†\")]:\n",
    "        print(f\"\\n{space_name}\")\n",
    "        print(\"=\" * 50)\n",
    "        for target, w1, w2, pair in CASES:\n",
    "            obs = vecs[:, idx[target]] - vecs[:, idx[w1]] - vecs[:, idx[w2]]\n",
    "            rho = log(p_given_c[target]) - log(p_cW[pair])\n",
    "            p_w1c = np.array([p_given_c[c][idx[w1]] for c in idx])\n",
    "            p_w2c = np.array([p_given_c[c][idx[w2]] for c in idx])\n",
    "            sigma = log(p_Wc[pair]) - log(p_w1c) - log(p_w2c)\n",
    "            tau = log(p_W[pair]) - log(p_w[idx[w1]]) - log(p_w[idx[w2]])\n",
    "            residual = np.linalg.norm(obs - project(rho + sigma - tau))\n",
    "            print(f\"{target} = {w1} + {w2}\")\n",
    "            print(f\"  ||ρ||={np.linalg.norm(rho):.2f}, ||σ||={np.linalg.norm(sigma):.2f}, |τ|={np.abs(tau):.4f}\")\n",
    "            print(f\"  residual: {residual:.6f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"ANALOGY: king - man + woman → ?\")\n",
    "    analogy = W[:, idx['king']] - W[:, idx['man']] + W[:, idx['woman']]\n",
    "    dists = [np.linalg.norm(analogy - W[:, i]) for i in range(n)]\n",
    "    for r, i in enumerate(np.argsort(dists)[:5]):\n",
    "        print(f\"  {r+1}. {vocab[i]:<12} dist={dists[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PMI space\n",
      "==================================================\n",
      "king = man + <royalty>\n",
      "  ||ρ||=0.14, ||σ||=17.31, |τ|=0.0020\n",
      "  residual: 0.000000\n",
      "queen = woman + <royalty>\n",
      "  ||ρ||=0.14, ||σ||=17.31, |τ|=0.0030\n",
      "  residual: 0.000000\n",
      "\n",
      "Embedding space\n",
      "==================================================\n",
      "king = man + <royalty>\n",
      "  ||ρ||=0.14, ||σ||=17.31, |τ|=0.0020\n",
      "  residual: 0.000000\n",
      "queen = woman + <royalty>\n",
      "  ||ρ||=0.14, ||σ||=17.31, |τ|=0.0030\n",
      "  residual: 0.000000\n",
      "\n",
      "==================================================\n",
      "ANALOGY: king - man + woman → ?\n",
      "  1. queen        dist=0.0382\n",
      "  2. <royalty>    dist=3.1992\n",
      "  3. royalty_17   dist=4.1569\n",
      "  4. royalty_16   dist=4.1580\n",
      "  5. royalty_19   dist=4.1598\n"
     ]
    }
   ],
   "source": [
    "N = 1_000_000\n",
    "counts, paired_counts, target_conditioned_counts = generate_data(n_windows=N, seed=42, scale=10)\n",
    "PMI, p_cw, p_w, p_c_given_W, p_W, W, C_dag, word2idx = build_all(\n",
    "    counts, paired_counts, target_conditioned_counts, N, rank=5\n",
    ")\n",
    "verify(PMI, p_cw, p_w, p_c_given_W, p_W, W, C_dag, word2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results:**\n",
    "\n",
    "With proper construction:\n",
    "- $\\|\\rho\\| \\approx 0$ (paraphrase holds)\n",
    "- $|\\tau| \\approx 0$ (marginal independence)\n",
    "- Residual $= 0$ (Lemma 1 verified exactly)\n",
    "- Analogy \"king - man + woman\" → queen ranks #1\n",
    "\n",
    "Note, $\\sigma$ isn't zero and it is very hard to make it so. Try to invent custom sampling data with $\\sigma \\approx 0$ to understand why \n",
    "it is so hard :)\n",
    "\n",
    "PS/ $x$ doesn't actually have to lead $\\tau = 0$ - thanks to symmetry in our data\n",
    "we would still have residual even if $\\tau \\neq 0$ (we would only have some difficulties with\n",
    "smoothing and making $\\rho \\approx 0$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes on Constants\n",
    "\n",
    "### Why x = 1/6?\n",
    "\n",
    "We chose x = 1/6 to make τ = 0 (marginal independence: p(man, royalty) = p(man)·p(royalty)).\n",
    "\n",
    "Let p = 5x be the probability of sampling a single target. Then:\n",
    "- p(man) = p/5 + (1-p)/2\n",
    "- p(royalty) = p/5 + (1-p)\n",
    "- p(man, royalty) = (1-p)/2\n",
    "\n",
    "Solving p(man)·p(royalty) = p(man, royalty) gives x = 1/6.\n",
    "\n",
    "Note: This choice is convenient but not essential. Due to symmetry in our construction (man/woman and king/queen are parallel), we have τ_king ≈ τ_queen, so their difference cancels in the analogy regardless of the individual τ values.\n",
    "\n",
    "### Smoothing Constants\n",
    "\n",
    "Laplace smoothing (α) prevents log(0) but must be applied consistently. The issue: p(c|w) from the co-occurrence matrix and p(c|W) from triple counts use different normalizations.\n",
    "\n",
    "For unseen contexts with smoothing α:\n",
    "- From co-occurrence: p(c|w) ∝ α / (N + αn)\n",
    "- From triple counts: p(c|W) ∝ α / (|W|·N/2 + αn)\n",
    "\n",
    "These differ by a factor related to the paraphrase frequency. To match scales, we use 0.5α for p(c|W):\n",
    "```\n",
    "p(c|W) = (count + 0.5α) / (pair_count + αn/12)\n",
    "```\n",
    "\n",
    "Using identical smoothing for both inflates the residual — many tokens accumulate small biases that sum to a significant error."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
